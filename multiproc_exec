#!/usr/bin/env python
"""
Uses multiprocessing to execute independent tasks in parallel
using N processes.

Written for Python 3.

Donald E. Willcox
"""

import argparse
import shlex
from subprocess import Popen, PIPE
import multiprocessing

parser = argparse.ArgumentParser()
parser.add_argument('taskfile', type=str,
                    help=('Input file containing command-line tasks to execute, one per line.\n' +
                          'A sequence of dependent commands may be concatenated on the same line by double ampersands &&.'))
parser.add_argument('-n', '--nprocs', type=int,
                    help='Number of worker processes to use. Default is CPU count * 2.')
args = parser.parse_args()

def godo(cmd):
    try:
        # First, separate dependent commands connected by &&
        cmd_seq = cmd.split('&&')
        out_seq = []
        err_seq = []
        # Execute each command in the command sequence
        for cmd in cmd_seq:
            print(cmd)
            # First, facilitate shell=False by passing cmd
            # through shlex.split()
            cmd_lex = shlex.split(cmd)
            # Execute cmd by supplying it to Popen
            proc = Popen(cmd_lex, stdout=PIPE, stderr=PIPE)
            out, err = proc.communicate()
            # Decode and return (stdout, stderr)
            try:
                out_seq.append(out.decode('utf-8'))
            except:
                out_seq.append('OUTPUT DECODE EXCEPTION FOR COMMAND {}'.format(cmd))
            try:
                err_seq.append(err.decode('utf-8'))
            except:
                err_seq.append('ERROR DECODE EXCEPTION FOR COMMAND {}'.format(cmd))
        return (out_seq, err_seq)
    except:
        print('ERROR IN GODO GIVEN CMD: {}'.format(cmd))
        raise

def initdo():
    # Print to notify this worker process is starting
    try:
        print('Init Worker Process: {}'.format(multiprocessing.current_process().name))
    except:
        print('ERROR IN INITDO!')
        raise

if __name__ == '__main__':
    # Get the list of tasks to execute
    todo = []
    ftasks = open(args.taskfile, 'r')
    for l in ftasks.readlines():
        ls = l.strip()
        if ls:
            todo.append(ls)
    ftasks.close()

    # Get the number of processors to use
    if args.nprocs:
        nprocs = args.nprocs
    else:
        nprocs = 2 * multiprocessing.cpu_count()

    # Map tasks to the multiprocessing pool
    mpool = multiprocessing.Pool(processes=nprocs,
                                 initializer=initdo)
    mpool_results = mpool.map(godo, todo)
    mpool.close()
    mpool.join()

    print('Completed Multiprocessed Execution')
    
    # Print each result
    nerr = 0
    print('Results:')
    for res, task in zip(mpool_results, todo):
        print('################################################################################')
        print('Task: {}'.format(task))
        out, err = res
        print('STDOUT:')
        for oi in out:
            try:
                print(oi)
            except:
                print('OUTPUT PRINT EXCEPTION!')
        print('STDERR:')
        for ei in err:
            try:
                print(ei)
            except:
                print('ERROR PRINT EXCEPTION!')
        if any(err):
            nerr += 1
        print('################################################################################')

    # Print result summary
    print('Result Summary:')
    print('{} Tasks Completed'.format(len(todo)))
    print('{} Tasks Yielded An Error'.format(nerr))

